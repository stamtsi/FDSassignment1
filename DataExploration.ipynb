{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if heavier emoji stripper is needed\n",
    "\n",
    "# def remove_emoji(string):\n",
    "#     emoji_pattern = re.compile(\"[\"\n",
    "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                                u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "#                                u\"\\U00002702-\\U000027B0\"\n",
    "#                                u\"\\U00002702-\\U000027B0\"\n",
    "#                                u\"\\U000024C2-\\U0001F251\"\n",
    "#                                u\"\\U0001f926-\\U0001f937\"\n",
    "#                                u\"\\U00010000-\\U0010ffff\"\n",
    "#                                u\"\\u2640-\\u2642\"\n",
    "#                                u\"\\u2600-\\u2B55\"\n",
    "#                                u\"\\u200d\"\n",
    "#                                u\"\\u23cf\"\n",
    "#                                u\"\\u23e9\"\n",
    "#                                u\"\\u231a\"\n",
    "#                                u\"\\ufe0f\"  # dingbats\n",
    "#                                u\"\\u3030\"\n",
    "#                                \"]+\", flags=re.UNICODE)\n",
    "#     return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_mentions(text):\n",
    "    text = re.sub(r'(^|[^@\\w])@(\\w{1,15})\\b', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_empty_tokens(text):\n",
    "    text = list(filter(None, text))\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = negative, 4 = positive\n",
    "\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1', header=None, names=['target', 'id', 'date', 'flag', 'user', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>unmentioned</th>\n",
       "      <th>depunctualized</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>improved_tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>@switchfoot  - Awww, that's a bummer.  You sho...</td>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "      <td>Awww thats a bummer  You shoulda got David ...</td>\n",
       "      <td>[, awww, thats, a, bummer, you, shoulda, got, ...</td>\n",
       "      <td>[awww, thats, a, bummer, you, shoulda, got, da...</td>\n",
       "      <td>[awww, thats, bummer, shoulda, got, david, car...</td>\n",
       "      <td>[awww, that, bummer, shoulda, got, david, carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "      <td>[upset, cant, updat, facebook, text, might, cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "      <td>I dived many times for the ball Managed to sa...</td>\n",
       "      <td>[, i, dived, many, times, for, the, ball, mana...</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, manage...</td>\n",
       "      <td>[dived, many, times, ball, managed, save, rest...</td>\n",
       "      <td>[dive, mani, time, ball, manag, save, rest, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "      <td>no its not behaving at all im mad why am i he...</td>\n",
       "      <td>[, no, its, not, behaving, at, all, im, mad, w...</td>\n",
       "      <td>[no, its, not, behaving, at, all, im, mad, why...</td>\n",
       "      <td>[behaving, im, mad, cant, see]</td>\n",
       "      <td>[behav, im, mad, cant, see]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0  @switchfoot  - Awww, that's a bummer.  You sho...   \n",
       "1  is upset that he can't update his Facebook by ...   \n",
       "2  @Kenichan I dived many times for the ball. Man...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                         unmentioned  \\\n",
       "0    - Awww, that's a bummer.  You shoulda got Da...   \n",
       "1  is upset that he can't update his Facebook by ...   \n",
       "2   I dived many times for the ball. Managed to s...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4   no, it's not behaving at all. i'm mad. why am...   \n",
       "\n",
       "                                      depunctualized  \\\n",
       "0     Awww thats a bummer  You shoulda got David ...   \n",
       "1  is upset that he cant update his Facebook by t...   \n",
       "2   I dived many times for the ball Managed to sa...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4   no its not behaving at all im mad why am i he...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [, awww, thats, a, bummer, you, shoulda, got, ...   \n",
       "1  [is, upset, that, he, cant, update, his, faceb...   \n",
       "2  [, i, dived, many, times, for, the, ball, mana...   \n",
       "3  [my, whole, body, feels, itchy, and, like, its...   \n",
       "4  [, no, its, not, behaving, at, all, im, mad, w...   \n",
       "\n",
       "                                  improved_tokenized  \\\n",
       "0  [awww, thats, a, bummer, you, shoulda, got, da...   \n",
       "1  [is, upset, that, he, cant, update, his, faceb...   \n",
       "2  [i, dived, many, times, for, the, ball, manage...   \n",
       "3  [my, whole, body, feels, itchy, and, like, its...   \n",
       "4  [no, its, not, behaving, at, all, im, mad, why...   \n",
       "\n",
       "                                             nonstop  \\\n",
       "0  [awww, thats, bummer, shoulda, got, david, car...   \n",
       "1  [upset, cant, update, facebook, texting, might...   \n",
       "2  [dived, many, times, ball, managed, save, rest...   \n",
       "3            [whole, body, feels, itchy, like, fire]   \n",
       "4                     [behaving, im, mad, cant, see]   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [awww, that, bummer, shoulda, got, david, carr...  \n",
       "1  [upset, cant, updat, facebook, text, might, cr...  \n",
       "2  [dive, mani, time, ball, manag, save, rest, go...  \n",
       "3             [whole, bodi, feel, itchi, like, fire]  \n",
       "4                        [behav, im, mad, cant, see]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no_urls'] = df['text'].apply(lambda x: remove_urls(x)) #remove urls\n",
    "df['unmentioned'] = df['no_urls'].apply(lambda x: remove_mentions(x)) #remove mentions\n",
    "df['depunctualized'] = df['unmentioned'].apply(lambda x: remove_punct(x)) #remove punctuations\n",
    "df['tokenized'] = df['depunctualized'].apply(lambda x: tokenization(x.lower())) #tokenize\n",
    "df['improved_tokenized'] = df['tokenized'].apply(lambda x: remove_empty_tokens(x)) #remove empty tokens\n",
    "df['nonstop'] = df['improved_tokenized'].apply(lambda x: remove_stopwords(x)) #remove stopwords\n",
    "df['stemmed'] = df['nonstop'].apply(lambda x: stemming(x)) #stem the tokens\n",
    "df['rejoined'] = df['stemmed'].apply(lambda x: \" \".join(x)) #rejoin for vectorization\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract to numpy arrays\n",
    "\n",
    "y = df.target.to_numpy()\n",
    "X = df.rejoined.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 125577   97852 1405317 ...  384833 1256796  886573] TEST: [ 973223 1219492 1199777 ...  981249 1390133  169748]\n"
     ]
    }
   ],
   "source": [
    "#split into train (80%) and test (20%)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size=0.8)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_t = X[train_index], X[test_index]\n",
    "    y_train, y_t = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: [ 68126 127283  13240 ... 175548 304617 290349] Val: [ 87327 132810 267834 ...  87109 189623 270457]\n"
     ]
    }
   ],
   "source": [
    "#split test into test (10%) and val (10%)\n",
    "\n",
    "sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.5, train_size=0.5)\n",
    "\n",
    "for test_i, val_i in sss_val.split(X_t, y_t):\n",
    "    print(\"TEST:\", test_i, \"Val:\", val_i)\n",
    "    X_test, X_val = X_t[test_i], X_t[val_i]\n",
    "    y_test, y_val = y_t[test_i], y_t[val_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280000,) (1280000,) (160000,) (160000,) (160000,) (160000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape) #check if split sizes are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize the tweets\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(X_train) #fit the vectorizer\n",
    "\n",
    "X_train_vectorized = cv.transform(X_train)\n",
    "X_test_vectorized = cv.transform(X_test)\n",
    "X_val_vectorized = cv.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 160000 points : 37394\n"
     ]
    }
   ],
   "source": [
    "y_pred = MultinomialNB().fit(X_train_vectorized, y_train).predict(X_val_vectorized)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (X_val_vectorized.shape[0], (y_val != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7662875\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB().fit(X_train_vectorized, y_train) #final trained model\n",
    "mnb_predictions = mnb.predict(X_val_vectorized)\n",
    "mnb_accuracy = mnb.score(X_val_vectorized, y_val)\n",
    "print(mnb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "negative sentiment      0.756     0.786     0.771     80000\n",
      "positive sentiment      0.777     0.747     0.762     80000\n",
      "\n",
      "         micro avg      0.766     0.766     0.766    160000\n",
      "         macro avg      0.767     0.766     0.766    160000\n",
      "      weighted avg      0.767     0.766     0.766    160000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_val, mnb_predictions, digits=3, target_names=['negative sentiment', 'positive sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save trained model as pickle\n",
    "\n",
    "# filename = 'MNB_sentiment_classifier_model_lemmatized.sav'\n",
    "# with open(filename, 'wb') as f_out:\n",
    "#     pickle.dump((mnb, cv), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model from disk\n",
    "filename = 'MNB_sentiment_classifier_model_lemmatized.sav'\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on provided tweet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a subset of 30 tweets\n",
    "\n",
    "jsonlist = []\n",
    "c = 0\n",
    "with open('geotagged_tweets_20160812-0912.jsons', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        c+=1\n",
    "        jsonlist.append(json.loads(line))\n",
    "        if c == 30:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>unmentioned</th>\n",
       "      <th>depunctualized</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>improved_tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>rejoined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@theblaze @realDonaldTrump https://t.co/TY9DlZ...</td>\n",
       "      <td>@theblaze @realDonaldTrump</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@BarackObama @FBI@LORETTALYNCH ALL IN COLLUSIO...</td>\n",
       "      <td>@BarackObama @FBI@LORETTALYNCH ALL IN COLLUSIO...</td>\n",
       "      <td>@LORETTALYNCH ALL IN COLLUSION TOGETHER #NOJUS...</td>\n",
       "      <td>LORETTALYNCH ALL IN COLLUSION TOGETHER NOJUSTI...</td>\n",
       "      <td>[lorettalynch, all, in, collusion, together, n...</td>\n",
       "      <td>[lorettalynch, all, in, collusion, together, n...</td>\n",
       "      <td>[lorettalynch, collusion, together, nojustice,...</td>\n",
       "      <td>[lorettalynch, collus, togeth, nojustic, trump...</td>\n",
       "      <td>lorettalynch collus togeth nojustic trumppenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@theblaze @realDonaldTrump https://t.co/n050DB...</td>\n",
       "      <td>@theblaze @realDonaldTrump</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@HillaryClinton he will do in one year all the...</td>\n",
       "      <td>@HillaryClinton he will do in one year all the...</td>\n",
       "      <td>he will do in one year all the things you sho...</td>\n",
       "      <td>he will do in one year all the things you sho...</td>\n",
       "      <td>[, he, will, do, in, one, year, all, the, thin...</td>\n",
       "      <td>[he, will, do, in, one, year, all, the, things...</td>\n",
       "      <td>[one, year, things, done, eight]</td>\n",
       "      <td>[one, year, thing, done, eight]</td>\n",
       "      <td>one year thing done eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>CNN newday clear Trump deliberately throwing t...</td>\n",
       "      <td>[cnn, newday, clear, trump, deliberately, thro...</td>\n",
       "      <td>[cnn, newday, clear, trump, deliberately, thro...</td>\n",
       "      <td>[cnn, newday, clear, trump, deliberately, thro...</td>\n",
       "      <td>[cnn, newday, clear, trump, deliber, throw, ra...</td>\n",
       "      <td>cnn newday clear trump deliber throw racein kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @theblaze @realDonaldTrump https://t.co/TY9DlZ...   \n",
       "1  @BarackObama @FBI@LORETTALYNCH ALL IN COLLUSIO...   \n",
       "2  @theblaze @realDonaldTrump https://t.co/n050DB...   \n",
       "3  @HillaryClinton he will do in one year all the...   \n",
       "4  #CNN #newday clear #Trump deliberately throwin...   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0                        @theblaze @realDonaldTrump    \n",
       "1  @BarackObama @FBI@LORETTALYNCH ALL IN COLLUSIO...   \n",
       "2                        @theblaze @realDonaldTrump    \n",
       "3  @HillaryClinton he will do in one year all the...   \n",
       "4  #CNN #newday clear #Trump deliberately throwin...   \n",
       "\n",
       "                                         unmentioned  \\\n",
       "0                                                      \n",
       "1  @LORETTALYNCH ALL IN COLLUSION TOGETHER #NOJUS...   \n",
       "2                                                      \n",
       "3   he will do in one year all the things you sho...   \n",
       "4  #CNN #newday clear #Trump deliberately throwin...   \n",
       "\n",
       "                                      depunctualized  \\\n",
       "0                                                      \n",
       "1  LORETTALYNCH ALL IN COLLUSION TOGETHER NOJUSTI...   \n",
       "2                                                      \n",
       "3   he will do in one year all the things you sho...   \n",
       "4  CNN newday clear Trump deliberately throwing t...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                                               [, ]   \n",
       "1  [lorettalynch, all, in, collusion, together, n...   \n",
       "2                                               [, ]   \n",
       "3  [, he, will, do, in, one, year, all, the, thin...   \n",
       "4  [cnn, newday, clear, trump, deliberately, thro...   \n",
       "\n",
       "                                  improved_tokenized  \\\n",
       "0                                                 []   \n",
       "1  [lorettalynch, all, in, collusion, together, n...   \n",
       "2                                                 []   \n",
       "3  [he, will, do, in, one, year, all, the, things...   \n",
       "4  [cnn, newday, clear, trump, deliberately, thro...   \n",
       "\n",
       "                                             nonstop  \\\n",
       "0                                                 []   \n",
       "1  [lorettalynch, collusion, together, nojustice,...   \n",
       "2                                                 []   \n",
       "3                   [one, year, things, done, eight]   \n",
       "4  [cnn, newday, clear, trump, deliberately, thro...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0                                                 []   \n",
       "1  [lorettalynch, collus, togeth, nojustic, trump...   \n",
       "2                                                 []   \n",
       "3                    [one, year, thing, done, eight]   \n",
       "4  [cnn, newday, clear, trump, deliber, throw, ra...   \n",
       "\n",
       "                                            rejoined  \n",
       "0                                                     \n",
       "1      lorettalynch collus togeth nojustic trumppenc  \n",
       "2                                                     \n",
       "3                          one year thing done eight  \n",
       "4  cnn newday clear trump deliber throw racein kn...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the subset of tweets\n",
    "\n",
    "testframe = pd.DataFrame(test_input, columns=['text'])\n",
    "testframe['no_urls'] = testframe['text'].apply(lambda x: remove_urls(x)) #remove urls\n",
    "testframe['unmentioned'] = testframe['no_urls'].apply(lambda x: remove_mentions(x)) #remove mentions\n",
    "testframe['depunctualized'] = testframe['unmentioned'].apply(lambda x: remove_punct(x)) #remove punctuations\n",
    "testframe['tokenized'] = testframe['depunctualized'].apply(lambda x: tokenization(x.lower())) #tokenize\n",
    "testframe['improved_tokenized'] = testframe['tokenized'].apply(lambda x: remove_empty_tokens(x)) #remove empty tokens\n",
    "testframe['nonstop'] = testframe['improved_tokenized'].apply(lambda x: remove_stopwords(x)) #remove stopwords\n",
    "testframe['stemmed'] = testframe['nonstop'].apply(lambda x: stemming(x))\n",
    "testframe['rejoined'] = testframe['stemmed'].apply(lambda x: \" \".join(x))\n",
    "testframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lorettalynch collus togeth nojustic trumppenc',\n",
       " 'one year thing done eight',\n",
       " 'cnn newday clear trump deliber throw racein knew isi destabil mideast start wiraq invas',\n",
       " 'wouldnt recogn lie came mouth continu nevertrump',\n",
       " 'trump trumppenc makeamericagreatagain',\n",
       " 'kid know su someon that beauti thing human could anoth human',\n",
       " 'cofound isi crook evil lie witch live',\n",
       " 'want comparison tri maim vet pre amp post iraq pullout bar graph',\n",
       " 'total concur elect cra cra n corrupt gov mind blow trump last hope',\n",
       " 'issu idiot claim found isi trump go hell lie amp steal shame',\n",
       " 'cant stand ortak look windont settl teamgov youin',\n",
       " 'isnt rape alleg get attent caus seem probabl',\n",
       " 'stole white hous furnitur',\n",
       " 'gop plead w trump control behavior week want year terrifi nevertrump crazi',\n",
       " 'isi cofound hillari clinton obama also devil hillari sit left hand devil',\n",
       " 'come jesu meet earth suppos',\n",
       " 'hanniti think disbar ignor mr hamburg dishonest',\n",
       " 'stop worri msm lie focu econampimmampdfn ur spprtr alreadi know she scum amp msm tank',\n",
       " 'true us offici sell arm isi',\n",
       " 'wake dem hillari cofound isi',\n",
       " 'oh go channel damn husband',\n",
       " 'morningjo wonder mental member laugh amp clap alleg child rapist',\n",
       " 'dont hate democrat hate evil ideolog abort immigr proudli present good america',\n",
       " 'yr crazi perform due dementia clever plot btwn amp clinton bring gop def con',\n",
       " 'isi polici creat upris youareresponsiblehillari',\n",
       " 'republican pull shenanigan expel parti',\n",
       " 'heystop use mediaif bias dont useprint cabl',\n",
       " 'preach']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testinput = [tweet for tweet in testframe.rejoined.values if tweet] #drop empty tweets\n",
    "testinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize with the fitted vectorizer\n",
    "\n",
    "test_input_vectorized = cv.transform(testinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = mnb.predict(test_input_vectorized) #predict the sentiment of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>lorettalynch collus togeth nojustic trumppenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>one year thing done eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cnn newday clear trump deliber throw racein kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>wouldnt recogn lie came mouth continu nevertrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>trump trumppenc makeamericagreatagain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>kid know su someon that beauti thing human cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>cofound isi crook evil lie witch live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>want comparison tri maim vet pre amp post iraq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>total concur elect cra cra n corrupt gov mind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>issu idiot claim found isi trump go hell lie a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>cant stand ortak look windont settl teamgov youin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>isnt rape alleg get attent caus seem probabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>stole white hous furnitur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>gop plead w trump control behavior week want y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>isi cofound hillari clinton obama also devil h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>come jesu meet earth suppos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>hanniti think disbar ignor mr hamburg dishonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>stop worri msm lie focu econampimmampdfn ur sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>true us offici sell arm isi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>wake dem hillari cofound isi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>oh go channel damn husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>morningjo wonder mental member laugh amp clap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>dont hate democrat hate evil ideolog abort imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>yr crazi perform due dementia clever plot btwn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>isi polici creat upris youareresponsiblehillari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>republican pull shenanigan expel parti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>heystop use mediaif bias dont useprint cabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>preach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                              tweet\n",
       "0           4      lorettalynch collus togeth nojustic trumppenc\n",
       "1           0                          one year thing done eight\n",
       "2           0  cnn newday clear trump deliber throw racein kn...\n",
       "3           0   wouldnt recogn lie came mouth continu nevertrump\n",
       "4           4              trump trumppenc makeamericagreatagain\n",
       "5           4  kid know su someon that beauti thing human cou...\n",
       "6           0              cofound isi crook evil lie witch live\n",
       "7           0  want comparison tri maim vet pre amp post iraq...\n",
       "8           0  total concur elect cra cra n corrupt gov mind ...\n",
       "9           0  issu idiot claim found isi trump go hell lie a...\n",
       "10          0  cant stand ortak look windont settl teamgov youin\n",
       "11          0       isnt rape alleg get attent caus seem probabl\n",
       "12          0                          stole white hous furnitur\n",
       "13          0  gop plead w trump control behavior week want y...\n",
       "14          4  isi cofound hillari clinton obama also devil h...\n",
       "15          4                        come jesu meet earth suppos\n",
       "16          4    hanniti think disbar ignor mr hamburg dishonest\n",
       "17          0  stop worri msm lie focu econampimmampdfn ur sp...\n",
       "18          0                        true us offici sell arm isi\n",
       "19          4                       wake dem hillari cofound isi\n",
       "20          0                         oh go channel damn husband\n",
       "21          4  morningjo wonder mental member laugh amp clap ...\n",
       "22          0  dont hate democrat hate evil ideolog abort imm...\n",
       "23          4  yr crazi perform due dementia clever plot btwn...\n",
       "24          0    isi polici creat upris youareresponsiblehillari\n",
       "25          0             republican pull shenanigan expel parti\n",
       "26          0        heystop use mediaif bias dont useprint cabl\n",
       "27          4                                             preach"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment and stemmed tweet\n",
    "\n",
    "output = pd.DataFrame(testinput, test).reset_index()\n",
    "output.columns = ['sentiment', 'tweet']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@theblaze @realDonaldTrump https://t.co/TY9DlZ584c\n",
      "@BarackObama @FBI@LORETTALYNCH ALL IN COLLUSION TOGETHER #NOJUSTICE @realDonaldTrump #TrumpPence https://t.co/5GMNZq40V3\n",
      "@theblaze @realDonaldTrump https://t.co/n050DBSpv0\n",
      "@HillaryClinton he will do in one year all the things you should have done in eight\n",
      "#CNN #newday clear #Trump deliberately throwing this race,in 2007 he knew that #ISIS and destabilization of Mideast started w/Iraq invasion\n",
      "@realDonaldTrump, you wouldn't recognize a lie if it came from your own mouth, and they do continually. #NeverTrump https://t.co/pKSQM8yikm\n",
      "#Trump2016 #TrumpPence16 #MakeAmericaGreatAgain  https://t.co/l5UsYANVc9\n",
      "\"Kid, you know, suing someone? Thats the most beautiful thing 1 human being could do to another human being\" @funnyordie @realDonaldTrump😂💩s\n",
      "@HillaryClinton you ARE the co-founder of ISIS, you crooked, evil, lying, witch. How can you live with yourself?\n",
      "@Geraldanthro @NeilTurner_ @realDonaldTrump want to do a comparison try maimed Vets pre &amp; post Iraq pullout. Bar graph that. @washingtonpost\n",
      "@mike4193496 @realDonaldTrump I TOTALLY CONCUR!! This Election is just CRA CRA n Corruption in our Gov is Mind Blowing!! Trump= Last Hope!!!\n",
      "@realDonaldTrump @elsolarverde What issues? Your idiot claim that she \"founded\" ISIS? Trump will go to Hell for lying &amp; stealing. Shame!\n",
      "Can't stand @HillaryClinton or @realDonaldTrump?Take a look. They can win...don't settle. #15for15 #TeamGov #YouIn  https://t.co/YK336aaH98\n",
      "@CribBoss @WesSmith123 @realDonaldTrump why isn't his rape allegations getting more attention cause it's seeming more probable he did it\n",
      "@HillaryClinton @TeamUSA @realDonaldTrump was this before or after you stole the White House furniture?\n",
      "GOP pleading w Trump \"Just control your behavior for a few weeks, then do what you want for 4 years\" - Terrifying! #NeverTrump  #Crazy\n",
      "@HillaryClinton ISIS co-founder Hillary Clinton. Obama also he is the devil and Hillary sits at the left hand of the devil\n",
      "Come to Jesus meeting!!!! What on earth is that supposed to be? 😔 https://t.co/a3lOpTtFig\n",
      "@sherrilee7 @seanhannity @HillaryClinton #Hannity what do you think of being disbarred? You are ignorant Mr. Hamburg or just dishonest?\n",
      "@realDonaldTrump stop worrying about the MSM lies. Focus on econ&amp;imm&amp;dfns.  Ur spprtrs already know she's scum &amp; MSM is in the tank for her.\n",
      "Is it true? US officially selling arms to ISIS?@RT_Erdogan @econofpak @Asad_Umar @AsimBajwaISPR @HillaryClinton https://t.co/LyimNK4wV4\n",
      "@HFA @HillaryClinton wake up Dems Hillary is cofounder of Isis\n",
      "@HillaryClinton @TeamUSA @realDonaldTrump oh here you go again, channeling that damn husband of yours\n",
      "#morningjoe Have to wonder about the mentality of @NAHBhome members who laughed &amp; clapped at alleged child rapist @realDonaldTrump @JoeNBC\n",
      "I don't hate Democrats. I hate the evil ideology of abortion and immigration they so proudly present as good America https://t.co/eR6GLDhj1M\n",
      "@realDonaldTrump Is yr  crazy performance due to dementia or is this a very clever plot btwn you &amp; Clinton to bring down GOP. Defs a con\n",
      "2008 there was no #ISIS.  It was @BarackObama and @HillaryClinton policies that created the uprising. #YouareResponsibleHillary @FoxNews\n",
      "@LouDobbs @realDonaldTrump @FoxNews These Republicans pulling these shenanigans should be expelled from the party!!!\n",
      "Hey,stop using the media.If they are so biased against you don't use,print or cable. https://t.co/TOtgdmW7wC\n",
      "Preach! https://t.co/0E1MDwU48r\n"
     ]
    }
   ],
   "source": [
    "#pre cleaned tweet\n",
    "\n",
    "for i in testframe.text:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
