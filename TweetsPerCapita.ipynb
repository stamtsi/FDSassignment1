{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson import json_util, ObjectId\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup client\n",
    "\n",
    "def mongo_to_dataframe(mongo_data):\n",
    "\n",
    "    sanitized = json.loads(json_util.dumps(mongo_data))\n",
    "    normalized = json_normalize(sanitized)\n",
    "    df = pd.DataFrame(normalized)\n",
    "\n",
    "    return df\n",
    "  \n",
    "    \n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client.TwitterData\n",
    "collection = db.Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\"place.country_code\" : \"US\"}\n",
    "projection = {\"text\": 1, \"place.place_type\": 1, \"place.full_name\": 1, \"_id\": 0}\n",
    "\n",
    "# Get data from Mongo to Pandas\n",
    "cursor = collection.find(query, projection)\n",
    "df =  mongo_to_dataframe(cursor)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get state in seperate column\n",
    "df[\"state\"] = df[\"place.full_name\"].apply(lambda x: str(x).split(\", \")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "abbrev_us_state = dict(map(reversed, us_state_abbrev.items()))\n",
    "state_abbrevs = [\"USA\"] + [state for state in abbrev_us_state]\n",
    "\n",
    "def convert_states(x):\n",
    "    if x[\"state\"] == \"USA\":\n",
    "        try:\n",
    "            return us_state_abbrev[x[\"place.full_name\"].split(\", \")[0]]\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return x[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"state\"] = df.apply(lambda x: convert_states(x), axis=1)\n",
    "df = df[df[\"state\"].isin(state_abbrevs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_states = pd.DataFrame(df.groupby([\"state\"]).size().sort_values(ascending=False), columns=[\"tweet_count\"])\n",
    "tweets_by_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load population of states CSV\n",
    "pop = pd.read_csv(\"data/nst-est2019-alldata.csv\")\n",
    "pop = pop[pop[\"NAME\"].isin([state for state in us_state_abbrev])][[\"NAME\", \"POPESTIMATE2016\"]]\n",
    "pop.columns = [\"state_name\", \"pop_estimate_2016\"]\n",
    "pop[\"state\"] = pop[\"state_name\"].apply(lambda x: us_state_abbrev[x])\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_states = tweets_by_states.merge(pop, on=\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_states[\"tweet_per_capita\"] = tweets_by_states.apply(lambda x: x.tweet_count / x.pop_estimate_2016, axis=1)\n",
    "tweets_by_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load election turnouts for the states\n",
    "turn = pd.read_csv(\"data/2016_november_general_election__turnout_rates.csv\", sep=\";\")\n",
    "turn = turn[[\"State Abv\", \"Highest Office\", \"VEP Highest Office\"]]\n",
    "turn = turn[1:]\n",
    "turn.columns = [\"state\", \"highest_office\", \"turnout_percent\"]\n",
    "turn[\"highest_office\"] = turn[\"highest_office\"].apply(lambda x: int(x.replace(\",\", \"\")))\n",
    "turn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_states = tweets_by_states.merge(turn, on=\"state\")\n",
    "tweets_by_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_states[\"turnout\"] = tweets_by_states.turnout_percent.apply(lambda x: int(x.replace(\"%\", \"\")))\n",
    "tweets_by_states[\"tweet_per_vote\"] = tweets_by_states.apply(lambda x: x.tweet_count/int(x.highest_office), axis=1)\n",
    "tweets_by_states#.to_csv(\"tweets_by_states.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_state = tweets_by_states[[\"state\", \"state_name\", \"tweet_count\", \"pop_estimate_2016\", \"tweet_per_capita\"]]\n",
    "tweets_by_state.set_index(\"state\", inplace=True)\n",
    "tweets_by_state.sort_values(ascending=False, by=[\"tweet_per_capita\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import branca\n",
    " \n",
    "state_geo = os.path.join('data', 'us-states.json')\n",
    "state_data = tweets_by_states[[\"state\", \"tweet_per_capita\"]].copy()\n",
    "state_data[\"tweet_per_capita\"] = state_data.tweet_per_capita.apply(lambda x: x*100)\n",
    "\n",
    "# Initialize the map:\n",
    "m = folium.Map(location=[37, -102], zoom_start=5)\n",
    " \n",
    "# Add the color for the chloropleth:\n",
    "m.choropleth(\n",
    " geo_data=state_geo,\n",
    " name='choropleth',\n",
    " data=state_data,\n",
    " columns=['state', 'tweet_per_capita'],\n",
    " key_on='feature.id',\n",
    " fill_color='OrRd',\n",
    " fill_opacity=0.7,\n",
    " line_opacity=0.2,\n",
    " legend_name='Tweets per capita (%)'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    " \n",
    "# Save to html\n",
    "m.save('map.html')\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    " \n",
    "state_geo = os.path.join('data', 'us-states.json')\n",
    "state_data = tweets_by_states[[\"state\", \"turnout\"]].copy()\n",
    "\n",
    "# Initialize the map:\n",
    "m = folium.Map(location=[37, -102], zoom_start=5)\n",
    " \n",
    "# Add the color for the chloropleth:\n",
    "m.choropleth(\n",
    " geo_data=state_geo,\n",
    " name='choropleth',\n",
    " data=state_data,\n",
    " columns=['state', 'turnout'],\n",
    " key_on='feature.id',\n",
    " fill_color='OrRd',\n",
    " fill_opacity=0.7,\n",
    " line_opacity=0.2,\n",
    " legend_name='2016 general election turnout (%)'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    " \n",
    "# Save to html\n",
    "#m.save('map_turnout.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
